{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3.0.0_def_apply_sexism_classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPjyrC+fGyhCBK7X4UmBmOC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7tIhSB8fOrF","executionInfo":{"status":"ok","timestamp":1637434234875,"user_tz":-60,"elapsed":8793,"user":{"displayName":"Lorenzo Betti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04278478979303365527"}},"outputId":"2ee316a8-267f-492c-e057-714d374fc80f"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 4.3 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4B2DgSbvfdPc","executionInfo":{"status":"ok","timestamp":1637434262425,"user_tz":-60,"elapsed":27553,"user":{"displayName":"Lorenzo Betti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04278478979303365527"}},"outputId":"895073bd-0839-4e5d-d98f-7e4fe3951afe"},"source":["from google.colab import drive\n","#drive.mount(\"/content/drive/\")\n","drive._mount(\"/content/drive/\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"CRP1FW1hfgoY","executionInfo":{"status":"ok","timestamp":1637434402378,"user_tz":-60,"elapsed":69324,"user":{"displayName":"Lorenzo Betti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04278478979303365527"}}},"source":["# load scripts to run the sexism classifiers\n","!cp /content/drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/utils/reproduce_sexism_classifier/text_preprocessor.py .\n","!cp /content/drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/utils/reproduce_sexism_classifier/bert_wrapper_transformers_inference.py .\n","\n","# load the model checkpoint\n","!cp -r /content/drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/utils/reproduce_sexism_classifier/checkpoints/final_model .\n","\n","# load datset\n","!cp -r \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/\" .\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZS5D9ldfv2p","executionInfo":{"status":"ok","timestamp":1637434432389,"user_tz":-60,"elapsed":30026,"user":{"displayName":"Lorenzo Betti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04278478979303365527"}},"outputId":"9a4eb17d-f9f5-4adf-f5a7-056340e1142b"},"source":["import numpy as np\n","import re, glob\n","import pandas as pd\n","import os, shutil\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","from bert_wrapper_transformers_inference import FinetunedBertClassifier\n","\n","import nltk\n","nltk.download('stopwords')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"5464VfP0f3yj","executionInfo":{"status":"ok","timestamp":1637434692098,"user_tz":-60,"elapsed":819,"user":{"displayName":"Lorenzo Betti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04278478979303365527"}}},"source":["# functions to split the lyrics and generate the input of the classifier\n","def make_batches_of_line(lines, n_items=4, stride=2):\n","\n","    l = len(lines)\n","    line_batches = [\" \".join(lines[i:i+n_items]) for i in range(0, l, stride)]\n","    return line_batches\n","\n","def make_batch(line_batches, batch_size=64):\n","\n","    l = len(line_batches)\n","    for batch in [line_batches[i:i+batch_size] for i in range(0, l, batch_size)]:\n","        yield batch\n","\n","def clean_and_split_lyric(lyric):\n","    lyric = re.sub(\"\\(.*?\\)\", \"\", lyric)\n","    lyric = re.sub(\"_\", \"\", lyric)\n","\n","    lines = re.split(\"(?:\\n)+\", lyric)\n","    lines = [l.strip() for l in lines if l.strip()!='']\n","    lines = [l for l in lines if len(l.split())>3]\n","    lines\n","\n","    return lines\n","\n","def classify(model, lyric):\n","\n","    lines = clean_and_split_lyric(lyric)\n","    line_batches = make_batches_of_line(lines)\n","    sexist_lines = []\n","    for b in make_batch(line_batches):\n","\n","        preds = model.predict(b)\n","        \n","        sexist_lines_ = [(round(pred, 4), line_batch) for pred, line_batch in zip(preds, b) if pred>=0.5]\n","        sexist_lines.extend(sexist_lines_)\n","\n","    return sexist_lines"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMRYAROQf6_l","executionInfo":{"status":"ok","timestamp":1637434454836,"user_tz":-60,"elapsed":22453,"user":{"displayName":"Lorenzo Betti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04278478979303365527"}}},"source":["# call the model\n","model = FinetunedBertClassifier(from_checkpoint=\"final_model/checkpoint-153\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"zpdvvdE7f_LY","outputId":"c1ac90ee-d3c1-4d67-dba3-0febe6a914d3"},"source":["decades = [1960, 1970, 1980, 1990, 2000]\n","\n","for decade in decades:\n","    lyrics_person_df = pd.read_json(f\"dataset_10_no_duplicates/data_lyrics_person_decades/lyrics_{decade}.json.gz\",\n","                                    orient='records', lines=True)\n","    lyrics_group_df = pd.read_json(f\"dataset_10_no_duplicates/data_lyrics_group_decades/lyrics_{decade}.json.gz\",\n","                                    orient='records', lines=True)\n","\n","    lyrics_df = pd.concat([lyrics_person_df, lyrics_group_df])\n","\n","    if decade in [1990]: # split dataset in two\n","\n","        n_lyrics = lyrics_df.shape[0]\n","        n_lyrics_half = n_lyrics // 2\n","        lyrics_df1 , lyrics_df2 = lyrics_df[:n_lyrics_half], lyrics_df[n_lyrics_half:]\n","\n","        lyrics_df1.loc[:, 'sexist_lines'] = lyrics_df1.lyrics.progress_apply(lambda l: classify(model, l))\n","        lyrics_df1.drop(columns=['lyrics'])\n","        lyrics_df1.to_json(f\"lyrics_sexism_{decade}_first.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}_first.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","\n","        lyrics_df2.loc[:, 'sexist_lines'] = lyrics_df2.lyrics.progress_apply(lambda l: classify(model, l))\n","        lyrics_df2.drop(columns=['lyrics'])\n","        lyrics_df2.to_json(f\"lyrics_sexism_{decade}_second.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}_second.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","\n","    elif decade in [2000]:  # split dataset in four\n","        n_lyrics = lyrics_df.shape[0]\n","        n_lyrics_half = n_lyrics // 2\n","        lyrics_df1 , lyrics_df2 = lyrics_df[:n_lyrics_half], lyrics_df[n_lyrics_half:]\n","\n","        n_half_half = n_lyrics_half // 2\n","        lyrics_df11, lyrics_df12 = lyrics_df1[:n_half_half], lyrics_df1[n_half_half:]\n","        lyrics_df21, lyrics_df22 = lyrics_df2[:n_half_half], lyrics_df2[n_half_half:]\n","\n","        \n","        lyrics_df11.loc[:, 'sexist_lines'] = lyrics_df11.lyrics.progress_apply(lambda l: classify(model, l))\n","        lyrics_df11.drop(columns=['lyrics'])\n","        lyrics_df11.to_json(f\"lyrics_sexism_{decade}_first_first.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}_first_first.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","\n","\n","        lyrics_df12.loc[:, 'sexist_lines'] = lyrics_df12.lyrics.progress_apply(lambda l: classify(model, l))\n","        lyrics_df12.drop(columns=['lyrics'])\n","        lyrics_df12.to_json(f\"lyrics_sexism_{decade}_first_second.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}_first_second.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","\n","\n","        lyrics_df21.loc[:, 'sexist_lines'] = lyrics_df21.lyrics.progress_apply(lambda l: classify(model, l))\n","        lyrics_df21.drop(columns=['lyrics'])\n","        lyrics_df21.to_json(f\"lyrics_sexism_{decade}_second_first.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}_second_first.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","        \n","\n","        lyrics_df22.loc[:, 'sexist_lines'] = lyrics_df22.lyrics.progress_apply(lambda l: classify(model, l))\n","        lyrics_df22.drop(columns=['lyrics'])\n","        lyrics_df22.to_json(f\"lyrics_sexism_{decade}_second_second.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}_second_second.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","\n","\n","    else:\n","\n","        lyrics_df.loc[:, 'sexist_lines'] = lyrics_df.lyrics.progress_apply(lambda l: classify(model, l))\n","\n","        lyrics_df.drop(columns=['lyrics'])\n","        lyrics_df.to_json(f\"lyrics_sexism_{decade}.json\",\n","                                    orient='records', lines=True)\n","        shutil.copy(f\"lyrics_sexism_{decade}.json\", \"drive/MyDrive/Artistic_Content_Creation/WASABI_gender_experiments/WASABI_gender_experiments_definitive/dataset_10_no_duplicates/Results_sexism_detection\")\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/23378 [00:00<?, ?it/s]"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='171156' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 5:21:56]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23378/23378 [36:26<00:00, 10.69it/s]\n","100%|██████████| 35033/35033 [1:01:52<00:00,  9.44it/s]\n","100%|██████████| 41498/41498 [1:19:47<00:00,  8.67it/s]\n","100%|██████████| 46515/46515 [1:39:35<00:00,  7.78it/s]\n","/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.obj[key] = _infer_fill_value(value)\n","/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(ilocs[0], value)\n"," 41%|████      | 19020/46515 [39:06<41:33, 11.03it/s]"]}]},{"cell_type":"code","metadata":{"id":"aG-fvp9MiZN5"},"source":[""],"execution_count":null,"outputs":[]}]}